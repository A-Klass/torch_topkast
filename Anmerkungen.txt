Anmerkungen

ctx.needs_input_grad: Vektor der gleichen Länge wie Argumente in der forward-Methode (ausgenommen ctx)
                      Beschreibt ob der Input vom Gradienten betroffen ist.
backward(ctx, grad_output): grad_output ist der Wert für f_out in DL 2-3-slides-backprop
ctx.save_for_backward: Sichert Tensors die vom Gradienten betroffen sind.
ctx.var = var: um vom Gradienten nicht betroffene Sachen für den Backward pass zu sparen (masken)

backward(): Innerhalb sollte, für alles was es braucht, der Gradient ausgerechnet werden
            Output muss die gleiche Länge haben wie forward inputs (ohne ctx)